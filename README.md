# Dont-Overfit-Kaggle
This repository contains a solution to the Don't Overfit Kaggle Competition.
Link to the competition : https://www.kaggle.com/c/dont-overfit-ii/overview

My work in this script includes :
1. Different feature selection methods
  a. SelectFromModel
  b. SelectKBest
  c. RFE (Recursive Feature Elimination)
  d. SelectPercentile
  e. Mutual_info_classif
  
2. Different Classification models
  a. Logistic Regression
  b. Linear SVC
  c. Decision Tree Classifier
  d. Random Forest Classifier
  e. AdaBoost Classifier
  f. Gradient Boosted Classifier
  h. GLM (Surprising Results)
  

I have also included score for each result(train and test)

This competition has auc-roc as scoring method.
